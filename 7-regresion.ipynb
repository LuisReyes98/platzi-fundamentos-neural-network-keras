{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from keras import layers, models, optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = boston_housing.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
      "   3.9769    4.      307.       21.      396.9      18.72   ]\n",
      "15.2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Los datos tienen una diferencia numerica entre ellos muy grande unos\n",
    "396.9 y otros 0.539 , esto es por que quizas una diferencia de 100 en el sueldo no es mucho pero una diferencia de 5 en la edad es bastante\n",
    "\n",
    "por lo cual para evitar que la red le de mayor importancia a los valores mas altos debemos Normalizar los datos\n",
    "\"\"\"\n",
    "print(train_data[0])\n",
    "print(train_labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizando los datos\n",
    "\n",
    "# les restamos la media\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data = train_data - mean\n",
    "\n",
    "# y dividimos entre la desviacion estandar\n",
    "std = train_data.std(axis=0)\n",
    "train_data = train_data / std\n",
    "\n",
    "# de esta forma normalizamos todos los datos para que esten entre 0 y 1\n",
    "\n",
    "\"\"\"\n",
    "usamos el mismo valor de train y std de train\n",
    "para test por razones eticas, yo jamas\n",
    "deberia darle a la data que voy a probar informacion que\n",
    "haga que se comporte diferente a la data con la que  entrene la red\n",
    "\n",
    "por lo cual no debo normalizar con la data de test ya que se supo que al soltar la red en el mundo real esa data no la tengo por lo cual no debo entrenar como si la tuviera\n",
    "\"\"\"\n",
    "test_data = test_data - mean\n",
    "test_data = test_data / std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.27224633, -0.48361547, -0.43576161, -0.25683275, -0.1652266 ,\n",
       "       -0.1764426 ,  0.81306188,  0.1166983 , -0.62624905, -0.59517003,\n",
       "        1.14850044,  0.44807713,  0.8252202 ])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.55369355, -0.48361547,  1.0283258 , -0.25683275,  1.03838067,\n",
       "        0.23545815,  1.11048828, -0.93976936,  1.67588577,  1.5652875 ,\n",
       "        0.78447637, -3.48459553,  2.25092074])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_regression(lr_var, input_data):\n",
    "  model = models.Sequential()\n",
    "\n",
    "  model.add(\n",
    "    layers.Dense(\n",
    "      64,\n",
    "      activation='relu',\n",
    "      input_shape=(input_data)\n",
    "    )\n",
    "  )\n",
    "\n",
    "  model.add(\n",
    "    layers.Dense(\n",
    "      64,\n",
    "      activation='relu'\n",
    "    )\n",
    "  )\n",
    "\n",
    "  model.add(\n",
    "    layers.Dense(1)\n",
    "  )\n",
    "\n",
    "  model.compile(\n",
    "    optimizer=optimizers.RMSProp(\n",
    "      lr=lr_var,\n",
    "      loss='mse',\n",
    "      metrics=['mae']\n",
    "    )\n",
    "  )\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 set de validacion\n",
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 80\n",
    "all_history = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
