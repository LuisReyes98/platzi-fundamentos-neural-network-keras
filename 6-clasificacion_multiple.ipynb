{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import reuters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 0s 0us/step\n",
      "565248/550378 [==============================] - 0s 0us/step\n",
      "None\n",
      "None\n",
      "None\n",
      "said\n",
      "as\n",
      "a\n",
      "result\n",
      "of\n",
      "its\n",
      "december\n",
      "acquisition\n",
      "of\n",
      "space\n",
      "co\n",
      "it\n",
      "expects\n",
      "earnings\n",
      "per\n",
      "share\n",
      "in\n",
      "1987\n",
      "of\n",
      "1\n",
      "15\n",
      "to\n",
      "1\n",
      "30\n",
      "dlrs\n",
      "per\n",
      "share\n",
      "up\n",
      "from\n",
      "70\n",
      "cts\n",
      "in\n",
      "1986\n",
      "the\n",
      "company\n",
      "said\n",
      "pretax\n",
      "net\n",
      "should\n",
      "rise\n",
      "to\n",
      "nine\n",
      "to\n",
      "10\n",
      "mln\n",
      "dlrs\n",
      "from\n",
      "six\n",
      "mln\n",
      "dlrs\n",
      "in\n",
      "1986\n",
      "and\n",
      "rental\n",
      "operation\n",
      "revenues\n",
      "to\n",
      "19\n",
      "to\n",
      "22\n",
      "mln\n",
      "dlrs\n",
      "from\n",
      "12\n",
      "5\n",
      "mln\n",
      "dlrs\n",
      "it\n",
      "said\n",
      "cash\n",
      "flow\n",
      "per\n",
      "share\n",
      "this\n",
      "year\n",
      "should\n",
      "be\n",
      "2\n",
      "50\n",
      "to\n",
      "three\n",
      "dlrs\n",
      "reuter\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "for _ in train_data[0]:\n",
    "  # las primeras 3 palabras del word index son palabras reservadas\n",
    "  print(word_index.get(_ - 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debemos volver la lista del dataset\n",
    "# a tensores para que la red los pueda entender\n",
    "def vectorize(sequences, dim=10000):\n",
    "  results = np.zeros((len(sequences), dim))\n",
    "  for i, sequences in enumerate(sequences):\n",
    "    results[i, sequences] = 1\n",
    "  return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorize(train_data)\n",
    "x_test = vectorize(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(\n",
    "  layers.Dense(\n",
    "    64,\n",
    "    activation='relu',\n",
    "    input_shape=(10000,)\n",
    "  )\n",
    ")\n",
    "model.add(\n",
    "  layers.Dense(\n",
    "    64,\n",
    "    activation='relu'\n",
    "  )\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "No usamos sigmoid porque la relacion binaria de 0 a 1 no me permitiria\n",
    "realizar clasificacion multiple\n",
    "\n",
    "en su lugar la funcion sigmoid, con una relacion de -1 a 1 nos permite\n",
    "clasificar cada una de las posibles salidas sin importar la cantidad\n",
    "en base a la relacion de ser y no ser una categoria\n",
    "\"\"\"\n",
    "model.add(\n",
    "  layers.Dense(\n",
    "    46,\n",
    "    activation='softmax'\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='rmsprop',\n",
    "  loss='categorical_crossentropy',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = y_train[:1000]\n",
    "partial_y_train = y_train[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
